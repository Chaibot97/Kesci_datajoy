watchlist = list(train = mt_xgb$train),
verbose = 1,
print_every_n = 50
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 8,
subsample = 0.8,
colsample_bytree = 0.5,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.5,
lambda = 25
)
model_xgb <- xgb.train(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1000,
early_stopping_rounds = 50,
maximize = FALSE,
watchlist = list(train = mt_xgb$train),
verbose = 1,
print_every_n = 50
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 8,
subsample = 0.8,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.5,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1000,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
model_xgb <- xgb.train(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
watchlist = list(train = mt_xgb$train),
verbose = 1,
print_every_n = 50
)
dt_full$train[, margin_xgb := predict(
model_xgb, mt_xgb$train, ntreelimit = model_xgb$best_ntreelimit
)]
dt_full$test[, margin_xgb := predict(
model_xgb, mt_xgb$test, ntreelimit = model_xgb$best_ntreelimit
)]
my.mse <- function(y, y_hat) {
mean((y - y_hat)^2)
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_xgb)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 8,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.5,
lambda = 25
)
model_xgb <- xgb.train(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
watchlist = list(train = mt_xgb$train),
verbose = 1,
print_every_n = 50
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 8,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
# gamma = 0.5,
lambda = 25
)
model_xgb <- xgb.train(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
watchlist = list(train = mt_xgb$train),
verbose = 1,
print_every_n = 50
)
dt_full$train[, margin_xgb := predict(
model_xgb, mt_xgb$train, ntreelimit = model_xgb$best_ntreelimit
)]
dt_full$test[, margin_xgb := predict(
model_xgb, mt_xgb$test, ntreelimit = model_xgb$best_ntreelimit
)]
my.mse <- function(y, y_hat) {
mean((y - y_hat)^2)
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_xgb)
fwrite(dt_full$test[, .(id, satisfaction_level = margin_xgb)], "test.csv")
dt_full$test[, .(id, satisfaction_level = margin_xgb)] %>% head()
dir()
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 8,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 5,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 200,
gamma = 0.15,
lambda = 30
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 5,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 500,
gamma = 0.25,
lambda = 30
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 5,
subsample = 0.5,
colsample_bytree = 0.8,
colsample_bylevel = 0.8,
min_child_weight = 300,
gamma = 0.2,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.35,
colsample_bytree = 0.5,
colsample_bylevel = 0.8,
min_child_weight = 300,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.5,
colsample_bytree = 0.7,
colsample_bylevel = 0.9,
colsample_bynode = 0.9,
min_child_weight = 250,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.45,
colsample_bytree = 0.7,
colsample_bylevel = 0.9,
colsample_bynode = 0.9,
min_child_weight = 250,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 250,
gamma = 0.1,
lambda = 25
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
args_xgb <- list(
objective = "reg:squarederror",
eval_metric = "rmse",
eta = 0.05,
max_depth = 6,
subsample = 0.75,
colsample_bytree = 0.75,
min_child_weight = 300,
gamma = 0.15,
lambda = 20
)
cv_xgb <- xgb.cv(
params = args_xgb,
data = mt_xgb$train,
nrounds = 1024,
early_stopping_rounds = 50,
maximize = FALSE,
verbose = 1,
print_every_n = 50,
nfold = 5,
showsd = TRUE
)
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
model_glmnet <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.5,
lambda = cv_glmnet$lambda.1se
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$test[, margin_glmnet := predict(model_glmnet, mt_glmnet$test)]
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
?glmnet
model_glmnet <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$test[, margin_glmnet := predict(model_glmnet, mt_glmnet$test)]
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
for (i in 1:5) {
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, weight]
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
for (i in 1:5) {
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
for (i in 1:5) {
print(i)
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
for (i in 1:20) {
print(i)
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
for (i in 1:20) {
print(i)
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet_ada, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
for (i in 1:20) {
print(i)
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.8,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet_ada, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
dt_full$train$abs_loss_glmnet^2 %>% mean()
model_glmnet <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$test[, margin_glmnet := predict(model_glmnet, mt_glmnet$test)]
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
for (i in 1:20) {
print(dt_full$train[, mean(abs_loss_glmnet^2)])
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.8,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet := predict(model_glmnet_ada, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
model_glmnet <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.2,
lambda = cv_glmnet$lambda.1se
)
dt_full$train[, margin_glmnet := predict(model_glmnet, mt_glmnet$train)]
dt_full$test[, margin_glmnet := predict(model_glmnet, mt_glmnet$test)]
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
for (i in 1:20) {
print(dt_full$train[, mean(abs_loss_glmnet^2)])
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.8,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet_ada := predict(model_glmnet_ada, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet_ada)]
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet_ada)
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet)
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet)]
for (i in 1:20) {
print(dt_full$train[, mean(abs_loss_glmnet^2)])
model_glmnet_ada <- glmnet(
mt_glmnet$train,
dt_full$train[[meta$target]],
alpha = 0.8,
lambda = cv_glmnet$lambda.1se,
weights = dt_full$train[, abs_loss_glmnet]
)
dt_full$train[, margin_glmnet_ada := predict(model_glmnet_ada, mt_glmnet$train)]
dt_full$train[, abs_loss_glmnet := abs(satisfaction_level - margin_glmnet_ada) * 10]
}
my.mse(dt_full$train$satisfaction_level, dt_full$train$margin_glmnet_ada)
head(dt_full$train[, .(abs_loss_glmnet, satisfaction_level)])
